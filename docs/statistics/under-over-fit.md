每种学习模型都有自己的假设和参数：

朴素贝叶斯：

* 假设：贝叶斯定理和变量之间的独立性
* 参数：各种先验概率和条件概率

决策树：

* 假设：假设是集合的纯净程度或者混乱程度
* 参数：各个树结点以及结点上的决策条件

拟合模型其实就是指通过模型的假设和训练样本，推导出具体参数的过程，然后就能对新数据做出预测。

## 举例说明

### 适度拟合

假设我们的数据点分布在一个二维空间，其中黑色的点表示训练数据所对应的点，x 轴表示唯一的自变量，y 轴表示因变量：

![](under-over-fit/pic-1.webp ":size=300")

根据这些训练数据，拟合回归模型之后，所得到的模型结果是一条黑色的曲线。有了这条曲线，我们就能根据测试数据的 x 轴取值（如图中的 x’）来获取 y 轴的取值（如图中的 y’），这种情况就是适度拟合（right fitting）:

![](under-over-fit/right-fit.webp ":size=300")

### 欠拟合

有的时候拟合得到的模型**过于简单**，和训练样本之间的误差非常大，这种情况就是**欠拟合**（Under Fitting），这种**拟合模型和训练样本之间的差异**，我们就称为**偏差**（Bias）：

![](under-over-fit/under-fit.webp ":size=300")

### 过拟合

另一种情况是，拟合得到的模型非常精细和复杂，和训练样本之间的误差非常小，我们称这种情况为过拟合（Over Fitting），比如下面这根黑色的曲线，和第一根曲线相比，离数据点的距离更近，也就是说偏差更小。

![](under-over-fit/over-fit.webp ":size=300")

过拟合的模型虽然在训练样本中表现得非常优越，但是在测试样本中可能表现不理想。

### 二维空间分类例子

类似地，我以二维空间里的分类为例。

适度拟合：

![](under-over-fit/right-fit-2.webp ":size=300")

欠拟合：

![](under-over-fit/under-fit-2.webp ":size=300")

过拟合：

![](under-over-fit/over-fit-2.webp ":size=300")

## 误差

一个算法既不可能和所有训练数据符合得分毫不差，也不可能对所有测试数据预测得精确无误。因而**误差性能就成为机器学习的重要指标之一**。

**在机器学习中，误差被定义为学习器的实际预测输出与样本真实输出之间的差异**。在分类问题中，常用的误差函数是**错误率**，即分类错误的样本占全部样本的比例。

误差可以进一步分为：

* **训练误差**指的是学习器在训练数据集上的误差，也称经验误差；训练误差描述的是输入属性与输出分类之间的相关性，能够判定给定的问题是不是一个容易学习的问题。
* **测试误差**指的是学习器在新样本上的误差，也称泛化误差。**测试误差则反映了学习器对未知的测试数据集的预测能力，是机器学习中的重要概念**。实用的学习器都是测试误差较低，即在新样本上表现较好的学习器。

整体来说测试误差与模型复杂度呈现的是抛物线关系，而训练误差和测试误差的关系则如下图表示：

![](under-over-fit/fit-evolution.webp ":size=550")

### 过拟合

学习器依赖已知数据对真实情况进行拟合，即由学习器得到的模型要尽可能逼近真实模型，因此要在训练数据集中尽可能提取出适用于所有未知数据的普适规律。

**然而，一旦过于看重训练误差，一味追求预测规律与训练数据的符合程度，就会把训练样本自身的一些非普适特性误认为所有数据的普遍性质，从而导致学习器泛化能力的下降，这就是过你和现象。**

* 产生的主要原因：特征维度过多，导致拟合的模型过于完美地符合训练样本，但是无法适应测试样本或者说新的数据。
* 解决办法：减少特征的维度

之前在介绍[决策树][1]的时候，提到了这类算法比较容易过拟合，可以使用[剪枝和随机森林](statistics/decision-tree)来缓解这个问题。

从另一个角度来看，过拟合表示模型太复杂，而相对的训练数据量太少。因此我们也可以增加训练样本的数据量，并尽量保持训练数据和测试数据分布的一致性。

### 欠拟合

与过拟合对应的是**欠拟合**，训练误差高，测试误差也高。

* 产生的主要原因：特征维度过少，拟合的模型不够复杂，无法满足训练样本，最终导致误差较大。
* 解决办法：增加特征维度，让输入的训练样本具有更强的表达能力

之前讲解[朴素贝叶斯][2]的时候，提到“任何两个变量是相互独立的假设”，这种假设和[马尔科夫假设][3]中的一元文法的作用一致，是为了降低数据稀疏程度、节省计算资源所采取的措施。可是，**这种假设在现实中往往不成立**，所以朴素贝叶斯模型的表达能力是非常有限的。**当我们拥有足够的计算资源，而且希望建模效果更好的时候，我们就需要更加精细、更加复杂的模型，朴素贝叶斯可能就不再适用了**。

### 交叉验证

交叉验证是一种选择测试误差最小模型的方法。

在模型选择中，为了对测试误差做出更加精确的估计，一种广泛使用的方法是**交叉验证**（Cross Validation）。交叉验证思想在于重复利用有限的训练样本，通过将数据切分成若干子集，让不同的子集分别组成训练集与测试集，并在此基础上反复进行训练、测试和模型选择，达到最优效果。

如果将训练数据集分成 10 个子集 D1−10 进行交叉验证，则需要对每个模型进行 10 轮训练，其中第 1 轮使用的训练集为 D2~D10 这 9 个子集，训练出的学习器在子集 D1 上进行测试；第 2 轮使用的训练集为 D1 和 D3~D10 这 9 个子集，训练出的学习器在子集 D2 上进行测试。依此类推，当模型在 10 个子集全部完成测试后，其性能就是 10 次测试结果的均值。**不同模型中平均测试误差最小的模型也就是最优模型**。

### 调参

调参是一种优化模型测试误差的方法。

除了算法本身，参数的取值也是影响模型性能的重要因素，同样的学习算法在不同的参数配置下，得到的模型性能会出现显著的差异。因此，**调参，也就是对算法参数进行设定，是机器学习中重要的工程问题，这一点在今天的神经网络与深度学习中体现得尤为明显。**

[1]: /statistics/decision-tree
[2]: /statistics/naive-bayes
[3]: /statistics/lang-model
